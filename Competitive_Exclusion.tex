\documentclass{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[pdftex]{graphicx}
\usepackage{showkeys}
\usepackage{fullpage}
\usepackage{cite}
\usepackage{palatino}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% START OF mymacros.sty
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath,amsthm,amssymb}


%Commonly used math commands
\newcommand{\conj}[1]{\overline{{#1}}}
\newcommand{\D}{\displaystyle}
\newcommand{\pd}[2]{\D\frac{\partial{#1}}{\partial{#2}}}  %Partial derivatives
\newcommand{\dd}[2]{\D\frac{d{#1}}{d{#2}}}  %Total derivatives
\newcommand{\ddd}[3]{\D\frac{d^{{#3}}{#1}}{d{#2}^{{#3}}}}  %Total derivatives
\newcommand{\pdtwo}[3]{\D\frac{\partial^2{#1}}{\partial{#2}\partial{#3}}}
\newcommand{\pdd}[3]{\D\frac{\partial^{{#3}}{{#1}}}{\partial{{#2}}^{{#3}}}}
%\newcommand{\qed}{$\blacksquare$}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}




%Theorem-like environments
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{define}[thm]{Definition}
\newtheorem{rmk}[thm]{Remark}
\newtheorem{exercise}[thm]{Exercise}
\newtheorem{soln}[thm]{Solution}
%\newenvironment{proof}{{\bf Proof.}  }{\hfill$\blacksquare$\\}

%Shorthand for Greek letters
\renewcommand{\a}{\alpha}
\renewcommand{\b}{\beta}
\newcommand{\g}{\gamma}
\renewcommand{\d}{\delta}
\newcommand{\eps}{\epsilon}
\renewcommand{\k}{\kappa}
\newcommand{\lam}{\lambda}
\newcommand{\n}{\nu}
\newcommand{\rh}{\rho}
\newcommand{\s}{\sigma}
\renewcommand{\t}{\tau}
\renewcommand{\th}{\theta}


%Formatting shorthand commands
\newcommand{\1}{\mathbf{1}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\av}[1]{\left|{#1}\right|}
\newcommand{\avg}[1]{\left\langle{#1}\right\rangle}
\newcommand{\dt}{{\mathit \Delta}t}
\newcommand{\dx}{{\mathit \Delta}x}
\newcommand{\iD}{{\mathit{\Delta}}}
\newcommand{\ip}[2]{\left\langle{{#1}},{{#2}}\right\rangle}
\newcommand{\norm}[1]{\left\|{#1}\right\|}
\renewcommand{\l}{\left}
\newcommand{\q}{\quad}
\renewcommand{\r}{\right}
\newcommand{\Ref}[1]{(\ref{#1})}

%Environment names 

\newcommand{\be}{\begin{enumerate}}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\ii}{\item}

%Vector symbols
\newcommand{\spn}{\mathrm{span}}
\newcommand{\x}{{\mathbf {{x}}}}
\newcommand{\y}{{\mathbf {{y}}}}
\newcommand{\z}{{\mathbf {{z}}}}
\newcommand{\e}{{\mathbf {{e}}}}
\newcommand{\cp}{{\mathbf {{r}}}}

%Probability macros
\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}

\newcommand{\diam}{\mathrm{diam}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\rg}{\mathrm{ran}}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% END OF mymacros.sty
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\title{Competitive Exclusion Problem}
\author{}

\begin{document}

\maketitle


\section{Problem Definition}


\begin{define}
Let $G=(V,E)$ be an undirected finite graph.  We will sometimes write $N = |V|$ and $M=|E|$ when necessary.

\be

\ii If $v,w\in V$, we define the distance between $v,w$, which we denote as $d(v,w)$, as the length of the shortest path between $v$ and $w$.

\ii The {\bf diameter} of $G$, denoted $\diam(G)$, is defined as 
\begin{equation*}
  \diam(G) = \max_{v,w} d(v,w).
\end{equation*}


\ee


\end{define}


\begin{exercise}
  Show that $\diam(G) \le N-1$.  Show an example where this bound is attained.  What is the minimum possible value for $\diam(G)$?
\end{exercise}
\begin{soln}
Suppose $\diam(G) = M \geq N$, then there exists $v,w$ so that $d(v,w) = M$.  There is a sequence $\{u_n\}_{n=1}^{M+1}$ so that $u_1 = v, u_{M+1} = w$, and $(u_n,u_{n+1}) \in E$ for each $1\leq n\leq M$.  But since $M+1 > N$ we have that by the ``pigeon hole principle'' there exists $1\leq i < j \leq M$ so that $u_i=u_j$.  But then the path $(u_1,u_2,...,u_{i-1},,u_j,u_{j+1},...,u_M,u_{M+1})$ is a path from $v$ to $w$ of length $M-(j-i)$.  But $d(v,w) = M$, a contradiction.  Thus $\diam(G) \le N-1$.  QED
\end{soln}

Let us define the following construction.  Choose a graph $G=(V,E)$, and define a function
\begin{equation*}
  f\colon\{0,1,\dots,diam(G)\}\to \R,
\end{equation*}
and then define the following system of differential equations:
\begin{equation}\label{eq:ODE}
  \frac{d}{dt}x_v = x_v (r_v - \sum_{w\in V} a_{vw} x_w),
\end{equation}
where
\begin{equation*}
  a_{vw} = f(d(v,w)),\quad r_v = \sum_{w\in V}a_{vw}.
\end{equation*}


\begin{exercise}
  The vector ${\bf 1} = (1,1,1,\dots,1)$ is always a fixed point of~\eqref{eq:ODE}.
\end{exercise}
\begin{soln}
\begin{eqnarray*}
	\frac{d}{dt}x_v = 1(r_v - \sum_{w\in V} a_{vw} 1) = r_v - r_v = 0, \mbox{ for each } v=1,2,...,N
\end{eqnarray*}
\end{soln}


\begin{exercise}\label{ex:Jacobian}
  Compute the Jacobian of~\eqref{eq:ODE} at $x={\bf 1}$.
\end{exercise}
\begin{soln}
Let $g_i(\x) = x_i (r_i - \sum_{j=1}^N a_{ij} x_j)$, then 
$$
\frac{\partial}{\partial x_j} g_i(\x) = 
\begin{cases}
-a_{ij} x_i,	&	\mbox{for } i \neq j \\
r_i - a_{ii} x_i - \sum_{k = 1}^N a_{ik} x_k,	&	\mbox{for } i = j  \\
\end{cases}
$$
and so
\begin{align*}
\frac{\partial}{\partial x_j} g_i(\1) = -a_{ij}.
\end{align*}
So the Jacobian at $\1$ is $-A$.
In general the Jacobian at $\x$ is 
\begin{align*}
\frac{\partial}{\partial x_j} g_i(\x) = (A(\1 - \x))_i \delta_{ij} - a_{ij} x_i \\
J(\x) = \diag((A(\1 - \x))) - \diag(\x) A.
\end{align*}

\end{soln}



The convention we should always use is that $f(0)\ge f(1)\ge f(2) \ge\dots\ge f(\diam(G)) \ge 0$.  As long as all of the $f$'s are nonnegative, then this is a competition model; as long as the function is decreasing then this means competition is strictest amongst closer neighbors.  Of course we can technically choose $f\equiv 0$ but this is a degenerate (and trivial) case, so let us always assume that $f(0)>0$.

Another way of writing~\eqref{eq:ODE} is as follows.  Let us define the operator $\odot\colon\R^N\times \R^N\to\R^N$ as follows:
\begin{equation*}
  (x\odot y)_i = x_iy_i.
\end{equation*}
In this sense, it is the ``dot-times'' operator of MATLAB.  Then we can write
\begin{equation*}
  \frac{d}{dt} \x = \x \odot (r-A \x).
\end{equation*}


\section{Case 1:  The ring}

Let us define the ring graph $R_N$ as the graph with $V=[N]$ and $(i,j)\in E$ iff $i=j\pm 1\pmod N$.  

\begin{exercise}
Show that $\diam(R_N) = \lfloor N/2 \rfloor$.
\end{exercise}
\begin{soln}
Case $\diam(R_N) \leq \lfloor N/2\rfloor$: \\
Assume $1 \leq i < j \leq N$, and let $k=j-i$.  
Then there are paths $(i,i+1,i+2,...,i+k-1,i+k)$ and $(j,j+1 \pmod N,...,j+N-k-1 \pmod N,j+N-k \pmod N)$ from $i$ to $j$ which are of lengths $k$ and $N-k$ respectively.  
Thus $d(i,j) \leq \min\{ k, N-k \} \leq \lfloor N/2\rfloor$.  
Since $i,j$ were arbitrary, $\diam(R_N) \leq \lfloor N/2\rfloor$. \\
Case $\diam(R_N) \geq \lfloor N/2\rfloor$: \\
Show $d(0,\lfloor N/2 \rfloor) = \lfloor N/2\rfloor$.  \\
Fix $k$.  Suppose there exists an $M$ and a path $(v_0=0,v_1,...,v_M=k)$ which does not contain all integers between $\{ 0,1,2,...,k \}$ or $\{ 0,N-1,N-2,...,k \}$.  
Then there exists $0<n<k<m<N$ so that $v_i \neq n,m$ for each $i$.  
Then $\exists i$ so that $v_i \in \{ m+1,...,N-1,0,1,...,n-1 \}$ and $v_{i+1} \in \{ n+1,...,k,...,m-1 \}$.  
But this is a contradiction as $v_i=v_{i+1} \pm 1 \pmod N$.  
Thus $d(0,k) \geq \min\{k,N-k \}$.  So $d(0,\lfloor N/2 \rfloor) = \lfloor N/2\rfloor$.
Thus $\diam(R_N) = \lfloor N/2\rfloor$.
\end{soln}


Big question right now:  for which functions $f$ is ${\bf 1}$ stable?  Said another way, when does the Jacobian computed in Exercise~\ref{ex:Jacobian} have all negative (or nonpositive) eigenvalues?

For convenience let us define $c_{N-k} := c_k$, for $k =1,2,...,,\lfloor N/2 \rfloor$.  
We will call the diameter of the graph $D:= \lfloor N/2 \rfloor$.
We will look into how convexity of $\{ c_0,c_1,...,c_D \}$ affects the stability of the system $\ref{eq:ODE}$.

Circulant matrices have eigenvalues of the form $\lambda_j = c_0 + c_{N-1} \omega_j + \cdots + c_1 \omega_j^{N-1}$ and eigenvectors $v_j = (1,\omega_j,\omega_j^2,...,\omega_j^{N-1})^T$ where $\omega_j = \exp(2\pi i j/N)$, and $i = \sqrt{-1}$.  
Note that $\omega_j^k +\omega_j^{N-k} = 2\cos(2\pi j k/N)$.  

There is another choice of eigenvectors that is often more convenient:  
$$
\begin{cases}
v_0 = \1 \\
v_j = (1,\cos(2\pi j 1/N),\cos(2\pi j 2/N),...,,\cos(2\pi j (N-1)/N))^T, \mbox{ for } 1 \leq j < N/2 \\
v_{N/2} = (1,-1,1,-1,...,1,-1)^T \mbox{ if } 2|N \\
v_{N-j} = (0,\sin(2\pi j 1/N),\sin(2\pi j 2/N),...,,\sin(2\pi j (N-1)/N))^T, \mbox{ for } 1 \leq j < N/2 \\
\end{cases}
$$

Then since $A$ is circulant the eigenvalues of $A$ are 
\begin{align} \label{lin e-val}
\lambda_j =& c_0 + c_{N-1} \omega_j + \cdots + c_1 \omega_j^{N-1} \nonumber \\
=& c_0 + \sum_{k=1}^{N-1} \cos(\frac{2\pi j}{N} k) c_k, 
\end{align}
for any $j$. 
So $\lambda_{N-j} = c_0 + \sum_{k=1}^{N-1} \cos(\frac{2\pi (N-j)}{N} k) c_k = \lambda_j$.

Now using the fact that $1 + \sum_{k=1}^{N-1} \cos(\frac{2\pi j}{N} k) = 0$ (for $j \neq 0$), we have that $\ref{lin e-val}$ becomes
\begin{align} \label{alt lin e-val}
\lambda_j = c_0 - c + \sum_{k=1}^{N-1} \cos(\frac{2\pi j}{N} k) (c_k-c) 	&	\mbox{ for any c $\in \R$, }
\end{align}
which is often more convenient.  

\begin{lem} \label{sum for lin dec f's}.
The series
$\sum_{k = 1}^{M-1} (M-k) \cos(\omega k) = -\frac{M}{2} + \frac{1}{2} \frac{1-\cos(M\omega)}{1-\cos(\omega)}$.
\end{lem}
\begin{proof}
Let $z = e^{i \omega }$.  Then 
\begin{align*}
\sum_{k = 1}^{M-1} (M-k) \cos(\omega k) &= \Re \left\{ \sum_{k = 1}^{M-1} (M-k) e^{i \omega k} \right\} \\
&= \Re \left\{ \sum_{k = 1}^{M-1} (M-k) z^k \right\} \\
&= \Re \left\{ \sum_{k = 1}^{M-1} M z^k - \sum_{k = 1}^{M-1} k z^k \right\} \\
&= \Re \left\{ \frac{M(z-z^M)}{1 - z} - \frac{z (1 - z^{M} -Mz^{M-1} + Mz^{M})}{(1-z)^2} \right\} \\
&= \Re \left\{ \frac{M(z-z^2-z^M+z^{M+1})}{(1 - z)^2} - \frac{(z - z^{M+1} -Mz^{M} + Mz^{M+1})}{(1-z)^2} \right\} \\
&= \Re \left\{ \frac{M(z-z^2)}{(1 - z)^2} - \frac{(z - z^{M+1})}{(1-z)^2} \right\} \\
&= \Re \left\{ \frac{Mz}{1 - z} + \frac{z^{M} - 1}{z^{-1}(1-z)^2} \right\} \\
&= \Re \left\{ \frac{M+Mz^{-1}}{(1 - z)(1 + z^{-1})} + \frac{z^{M} - 1}{2\cos(\omega)-2} \right\} \\
&= \frac{-M}{2} + \frac 12 \frac{1-\cos(M\omega)}{1-\cos(\omega)} \\
\end{align*}
\end{proof}

\begin{thm} \label{lin dec f's}.
Suppose $\{ c_0,c_1,...,c_M \}$ are linear and decreasing for $M \leq D$ and $c_M = c_{M+1} = \cdots = c_D = 0$.  
Then the eigenvalues of $A$ are $\lambda_j = \frac{1}{M} \frac{1- \cos(\frac{2\pi j}{N} M)}{1- \cos(\frac{2\pi j}{N})}$, for $j = \{ 1,...,N-1 \}$.
\end{thm}

\begin{proof}
Consider an integer $M \leq D$, and  $c_0-c_1= \cdots = c_{M-1} - c_M = \frac 1M, c_M = c_{M+1}= \cdots = c_{\lfloor \frac N2 \rfloor} = 0.$  
Now we have that the eigenvalues are 
\begin{align} \label{}
\lambda_j &= c_0 + \sum_{k=1}^{N-1} \cos(\frac{2\pi j}{N} k) c_k,  \nonumber \\
&= 1 + \frac 2M \sum_{k=1}^{M-1} (M-k)\cos(\frac{2\pi j}{N} k) \nonumber \\
&= \frac{1}{M} \frac{1- \cos(\frac{2\pi j}{N} M)}{1- \cos(\frac{2\pi j}{N})}.
\end{align}
See Lemma \ref{sum for lin dec f's} for the last equality.
\end{proof}

\begin{rmk} \label{rmk:gcd}
Now $\gcd(N,M) = 1$ if and only if we have a strict negative definite Jacobian.  
Indeed, if $\gcd(N,M) = 1$ then for $j \in  \{ 1,2,...,N-1 \}$, $\frac{Mj}{N} \notin \N$ and thus $\lambda_j = \frac{1}{M} \frac{1- \cos(\frac{2\pi j}{N} M)}{1- \cos(\frac{2\pi j}{N})} > 0$.
Also, $\lambda_0 = \sum_{k=0}^{N-1} c_k = 1$.
On the other hand if $\gcd(N,M) > 1$ we can let $j = \frac N{\gcd(N,M)} \in \{2,...,N-1 \}$.
Then one can check that $\lambda_j, \lambda_{N-j} = 0$.
Additionally, since $\omega_j^k +\omega_j^{N-k} = 2\cos(2\pi j k/N)$ we have that $v_j + v_{N-j} \in R^n$, thus $v_j + v_{N-j} \in \ker A$.

Now $v_j + v_{N-j} \in \ker A$ implies that $A (\alpha(v_j + v_{N-j}) + \1) = A \1$. 
Thus we have a hyperplane of fixed points.
\end{rmk}

\begin{thm} \label{e-val_convx_comb}
Consider the set $\{ c_0,c_1,...,c_D \}$.  
Define $\alpha_D = c_{D-1} - c_D$ and $\alpha_k = c_{k-1} - 2c_k +c_{k+1}$, for $k = 1,2,...,D-1$.  
Then the eigenvalues of $A$ are $\lambda_j = \sum_{i=1}^D \alpha_{i} \frac{1- \cos(\frac{2\pi j}{N} i)}{1- \cos(\frac{2\pi j}{N})}$ for $j \in  \{ 1,2,...,N-1 \}$.
\end{thm}

\begin{proof}
By \ref{alt lin e-val} we have that 
\begin{align} \label{e-vals_ring}
\lambda_j &= c_0-c_D + \sum_{k=1}^{N-1} \cos(\frac{2\pi j}{N} k) (c_k - c_D),  \nonumber \\
&= c_0-c_D + 2\sum_{k=1}^{D-1} \cos(\frac{2\pi j}{N} k) (c_k - c_D),  \nonumber \\
&= \sum_{i=1}^D i \alpha_i + 2\sum_{k=1}^{D-1} \cos(\frac{2\pi j}{N} k) \left[\sum_{i=k+1}^D(i-k)\alpha_i \right], \mbox{details left for the reader,} \nonumber \\
&= \sum_{i=1}^D i \alpha_i + 2\sum_{1 \leq k \leq i-1 \leq D-1} \cos(\frac{2\pi j}{N} k) (i-k)\alpha_{i}, \nonumber \\
&= \alpha_1 + \sum_{i=2}^D \left[i \alpha_i + 2\alpha_i \sum_{k=1}^{i-1} (i-k) \cos(\frac{2\pi j}{N} k) \right],  \nonumber \\
&= \sum_{i=1}^D \alpha_{i} \frac{1- \cos(\frac{2\pi j}{N} i)}{1- \cos(\frac{2\pi j}{N})}, \mbox{by lemma \ref{sum for lin dec f's}}.
\end{align}
\end{proof}

\begin{cor}
Suppose that $\{ c_0,c_1,...,c_D \}$ is convex and decreasing.  
That is $c_0-c_1 \geq \cdots \geq c_{D-1} - c_D \geq 0$, $\alpha_D = c_{D-1} - c_D \geq 0$, and $\alpha_k = c_{k-1} - 2c_k +c_{k+1} \geq 0$ for $k = 1,2,...,D-1$.  
Then $\lambda_j = \sum_{i=1}^M \alpha_{i} \frac{1- \cos(\frac{2\pi j}{N} i)}{1- \cos(\frac{2\pi j}{N})} \geq 0$ for $j \in  \{ 0,1,2,...,N-1 \}$.  
Also, $\gcd(N,\{ i: \alpha_i \neq 0 \}) = 1$ if and only if $A$ is positive definite.  
In particular, strict convexity gives us a stable fixed point.
\end{cor}
\begin{proof}
Apply Theorem \ref{e-val_convx_comb} and see Remark \ref{rmk:gcd}.
\end{proof}

\begin{cor}
Suppose that $\{ c_0,c_1,...,c_D \}$ is concave and decreasing.  
That is $c_0-c_1 \leq \cdots \leq c_{D-1} - c_D \leq 0$, $\alpha_D = c_{D-1} - c_D > 0$, and $\alpha_k = c_{k-1} - 2c_k +c_{k+1} \leq 0$ for $k = 1,2,...,D-1$.  
Then $\lambda_j = \sum_{i=1}^M \alpha_{i} \frac{1- \cos(\frac{2\pi j}{N} i)}{1- \cos(\frac{2\pi j}{N})}$ for $j \in  \{ 0,1,2,...,N-1 \}$.
Also if $N$ is even and $\{ c_0,c_1,...,c_D \}$ is not linear, then $\lambda_{2} < 0$.  

\end{cor}
\begin{proof}
Apply Theorem \ref{e-val_convx_comb} and see Remark \ref{rmk:gcd}.
\end{proof}

\begin{rmk}
Note that we cannot guaranty instability in general here, but we can say that having concave, decreasing $c_i's$ is equivalent to $\alpha_i \leq 0$ and $\alpha_M \geq \sum_{i=1}^M | \alpha_{i} |$, and so there always exists an $\omega \in [0,2 \pi)$ so that $\sum_{i=1}^M \alpha_{i} \frac{1- \cos(\omega i)}{1- \cos(\omega)} < 0$. 
Then we can ask whether or not a $j \in \N$ exists so that $\omega = \frac{2\pi j}{N}$.
\end{rmk}

Suppose we want to more carefully analyze the stability in the concave case.  
Then we might want a polynomial form for the sum $\sum_{i=1}^D \alpha_{i} \frac{1- \cos(\frac{2\pi j}{N} i)}{1- \cos(\frac{2\pi j}{N})}$.  
In general
$$
\cos(n \omega) = 2^{n-1} \cos^n(\omega) + n \sum_{k=1}^D \frac{(-1)^k}{k} {n-k-1\choose k-1} 2^{n-2k-1} \cos^{n-2k} (\omega),
$$
so we have that
$$
\alpha_n(1-\cos(n \omega)) = \alpha_n - \alpha_n 2^{n-1} \cos^n(\omega) - \alpha_n n \sum_{k=1}^D \frac{(-1)^k}{k} {n-k-1\choose k-1} 2^{n-2k-1} \cos^{n-2k} (\omega).
$$

Let $c_i := -\alpha_i 2^{i-1} -  2^{i-1}\sum_{k=1}^{\lfloor \frac{D-i}{2} \rfloor} \alpha_{i+2k} \frac{(-1)^k}{k} {i+k-1\choose k-1}$ 
and $c_0 := \sum_{k=1}^D \alpha_k -  2^{-1}\sum_{k=1}^{\lfloor \frac{D}{2} \rfloor} \alpha_{2k} \frac{(-1)^k}{k}$.  
Then we have that 
$$\sum_{i=1}^D c_i \cos^i\left(\frac{2\pi j}{N}\right) = \sum_{i=1}^D \alpha_{i} {\left(1- \cos \left( \frac{2\pi j}{N} i\right) \right)}.$$

We originally asked does the stability improve when edges are added to the graph.  
Here is an example were stability is in fact lost.  
Consider the graph $G_1 = R_6$ and let $G_2$ have edges $(1,3),(2,4),$ and $(1,5)$ in addition to $G_1$.  
Let $c_0 = 1.51, c_1 = 1, c_2 = .5, c_3 = .3$.
Then the corresponding matrices are
$$
\begin{pmatrix}
1.51 & 1 & .5 & .3 & .5 & 1 \\
1 & 1.51 & 1 & .5 & .3 & .5 \\
.5 & 1 & 1.51 & 1 & .5 & .3 \\
.3 & .5 & 1 & 1.51 & 1 & .5 \\
.5 & .3 & .5 & 1 & 1.51 & 1 \\
1 & .5 & .3 & .5 & 1 & 1.51 \\
\end{pmatrix} 
\mbox{ and }
\begin{pmatrix}
1.51 & 1 & 1 & .5 & 1 & 1 \\
1 & 1.51 & 1 & 1 & .5 & .5 \\
1 & 1 & 1.51 & 1 & .5 & .5 \\
.5 & 1 & 1 & 1.51 & 1 & .5 \\
1 & .5 & .5 & 1 & 1.51 & 1 \\
1 & .5 & .5 & .5 & 1 & 1.51 \\
\end{pmatrix}
$$
respectively.  
The first matrix has the following eigenvalues $\{  4.81,1.71,1.71,0.31,0.31,0.21 \}$ which are all positive as expected.
The second matrix has eigenvalues $\{ 5.52674,1.59281,1.06746,0.51,0.439637,-0.0766491 \}$ which contains a negative value and thus unstable.  
Thus the stability is lost after adding edges.

\section{Case 2:  Hamiltonian Cycles}

In this section we will attempt to generalize from rings to Hamiltonian cycles.  
This is a natural step from the ring as any Hamiltonian cycle may be written as a ring with added edges.  
Also the class of connected graphs which are Hamiltonian cycles is quite large.  

We will start by analyzing conditions of stability for graphs which come from adding an edge to a ring.  
In this section we will define $Q_A( \x ) := \frac{\ip{A\x}{\x}}{\ip{\x}{\x}}$ for a matrix $A$.

\begin{lem}
Suppose that $\{v^1,...,v^N \}$ are eigenvectors of a matrix $A$.  
Let $\lambda_1^A \leq...\leq \lambda_N^A $ and $ \lambda_1^B \leq...\leq \lambda_N^B $ be the eigenvalues of the two symmetric $N \times N$ matrices $A$ and $B$ respectively.  

Then $\lambda_k^B \geq \lambda_k^A$ if $\min_{\x \in U} Q_B(\x) \geq \min_{\x \in U} Q_A(\x)$ where $U := \spn \{ v^k,...,v^N \}$.  
\end{lem}
\begin{proof}
Apply Min-Max theorem.
\end{proof}

\begin{rmk}
Next thing I will do is add an example of \ref{1_edge} and illustrations and shit...
Also I will try to generalize \ref{1_edge} to all Hamiltonian cycles then I will prove that if $f$ is not of the form $c_0 \geq c_1 = c_2 = ... = c_D$ then there exists a graph with unstable behavior.
\end{rmk}

\section{Determinant of the $\alpha-\lambda$ matrix}

Theorem \ref{e-val_convx_comb} gives us a matrix $M_N = \l(\frac{1 - \cos(2 \pi i j/N)}{1 - \cos(2 \pi i/N)} \r)_{i,j = 1}^D$ so that
\begin{align} 
M_N 
\begin{pmatrix} 
\a_1 \\
\a_2 \\
\vdots \\
\a_D \\
\end{pmatrix} 
= 
\begin{pmatrix} 
\lam_1 \\
\lam_2 \\
\vdots \\
\lam_D \\
\end{pmatrix} .
\end{align}
For simplicity consider (prove later)
\begin{align*}
L_N :&= \l| \l(1 - \cos \l( \frac{2 \pi i j}{N} \r) \r)_{i,j = 1}^D \r|^2 \\
&= D \begin{pmatrix} 1 \\ 1 \\ \vdots \\ 1 \\ \end{pmatrix} \begin{pmatrix} 1 \\ 1 \\ \vdots \\ 1 \\ \end{pmatrix}^*
+ 2 \begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \\ \vdots \end{pmatrix} \begin{pmatrix} 1 \\ 0 \\ 1 \\ 0 \\ \vdots \end{pmatrix}^*
+ \diag \begin{pmatrix} D/2 \\ D/2 \\ \vdots \\ D/2 \end{pmatrix}
+ \frac{D}{2} \e_N \e_N^*.
\end{align*}

\section{Properties of the competitive Lotka-Volterra}
Given that $A = A^*$, $\cp = A \tilde{\x}$, and $\tilde{\x} \in \R_+^N$, consider the system $\dot{\x} = \x \odot (\cp - A \x)$.  Recall that the Jacobian is $J(\x) = \diag(A(\1 - \x)) - \diag(\x) A$ at $\x$.

Let $S \in \wp([N])$, and define the $|S| \times N$ matrix $Q_S = (\d_{\sigma(j),j})_{j \in S}$.  For example, 
\begin{align*} 
Q_{\{1,3,4\}} = 
\begin{pmatrix} 
1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix} 
\end{align*}
Define the following projection $P_S := Q_S^* Q_S \le I$, and note that $P_S = \diag( \sum_{i \in S} \e_i)$.  
\begin{define}
We say that $\x \in \R^N$ persists according to $S$ if $P_S \x = \x$ and $Q_S \x \in \R_{++}^N$.
\end{define}
Notice that for any $\x \in \R_+^N$, if $P_S \x = \x$ then the species corresponding to the set $[N] \setminus S$ are extinct. 
Moreover, if $Q_S \x \in \R_{++}^{|S|}$ then the species corresponding to the set $S$ are not extinct.
As an example consider $\x \in \R^4$,
\begin{align*} 
Q_S \x &= (x_1,x_3,x_4)^T \mbox{ and }\\
P_S \x &= (x_1,0,x_3,x_4)^T.
\end{align*}

Suppose that $\tilde{\x} = \1$ and $S$ is given, and define $A_S := Q_SA Q_S^*$, $\cp_S := Q_S \cp$, and $\x_S := Q_S \x$.
If $\x$ persists according to $S$, then the dynamics of $\dot{\x} = \x \odot (\cp - A \x)$ are equivalent to $\dot{\x}_S = \x_S \odot (\cp_S - A_S \x_S)$.
Indeed, 
\begin{align} \label{sub_dyn}
\dot{\x_S} = Q_S \dot{\x} = Q_S [\x \odot (\cp - A P_S \x)] = Q_S \x \odot (Q_S \cp - Q_SA Q_S^* Q_S \x) = \x_S \odot (\cp_S - A_S \x_S).
\end{align}
So if $\tilde \x_S$ fixes $\dot{\x}_S = \x_S \odot (\cp_S - A_S \x_S)$ then $Q_S^* \tilde \x_S$ fixes $\dot{\x} = \x \odot (\cp - A \x)$.
(Mention how the range isn't always obtained)

\begin{thm} \label{stable_sub}
Suppose we are given $S$ and that $A = A^*$.
If $\cp_S \in A_S(\R_{++}^N)$ and $A_S$ is positive definite, then $A_S^{-1} \cp_S$ is a stable fixed point in $P_S(\R_{++}^N)$ for the dynamical system $\dot{\x}_S = \x_S \odot (\cp_S - A_S \x_S)$.
\end{thm}

\begin{proof}
Let $\tilde{\x}_S = A_S^{-1} \cp_S$. 
Clearly $\tilde{\x}_S$ is a fixed point in $Q_S(\R_{++}^N)$, and $A_S$ is self-adjoint.
Consider the function $$V(\x_S) := (\x_S - \tilde{\x}_S)^*A_S(\x_S - \tilde{\x}_S)$$.
Then $V$ is radially unbounded and positive definite (w.r.t. $\x_S$).
Finally,
\begin{align*} 
\frac{d}{dt} [V(\x_S(t))] &= \sum_{i \in S} V_{x_S[i]}(\x_S) \frac{d x[i]}{dt} \\
&= \sum_{i \in S} 2[A_S(\x_S - \tilde{\x}_S)][i] x_S[i] [A_S(\tilde{\x}_S - \x_S)][i] \\
&= -\sum_{i \in S} 2 x_S[i] (A_S(\x_S - \tilde{\x}_S)[i])^2 \\
&<0.
\end{align*}
Thus $V$ is a Lyapunov function, and so $\tilde{\x}_S$ is a stable fixed point in $P_S(\R_{++}^N)$ for the dynamical system 
$\dot{\x}_S = \x_S \odot (\cp_S - A_S \x_S)$.
\end{proof}

\begin{thm} \label{incl_As}
Suppose $S_2 \subset S_1$ and $A_{S_1} > 0$, then $A_{S_2} > 0$.
\end{thm}

\begin{proof}
Inclusion Principle.
\end{proof}

\begin{thm} \label{exp_dec}
The population $x_i$ does not decay faster than exponentially.
\end{thm}

\begin{proof}
By (bounded theorem hasn't been written yet) there is a vector $\mathbf{b}$ so that
\begin{align*} 
\dot{x}_i = x_i \l( r_i - \sum_{j=1}^N A_{ij} x_j \r) \ge x_i \l( r_i - \sum_{j=1}^N A_{ij} b_j \r),
\end{align*}
hence the conclusion.
\end{proof}

\begin{thm} \label{largest_space}
Suppose $S_2 \subset S_1$, $A_1 >0$, and $\cp_1 \in A_1(\R_{++}^N)$. 
Then $Q_2^* A_2^{-1} \cp_2$ is not attracting in $\R_{++}^N$.
\end{thm}

\begin{proof}
Let $\tilde \x_2 = A_2^{-1} \cp_2$ and $\tilde \x_1 = A_1^{-1} \cp_1$. 
Now $Q_2^* \tilde \x_2$ fixes $\dot{\x} = \x \odot (\cp - A \x)$, so $Q_2 A (\1 - Q_2^* \tilde \x_2) = 0$.
Thus $\forall k \in S_2$ so that $\sum_{i \in [N]} A[i, k] (\1 - (Q_2^*\tilde \x_2) [i]) = 0$.

We want to show that $\exists k \in S_1 \setminus S_2$ so that $\sum_{i \in [N]} A[i, k] (\1 - (Q_2^*\tilde \x_2) [i]) > 0$. 
Suppose not.  Additionally, suppose that $\exists k \in S_1 \setminus S_2$ so that $\sum_{i \in [N]} A[i, k] (\1 - (Q_2^*\tilde \x_2) [i]) < 0$.
Then WLOG assume $S_1 = S_2 \cup \{k\}$.
By continuity there exists a neighborhood of $Q_2^* \x_2$ that is attracting in $Q_1(\R_+^N)$, a contradiction by theorem \ref{stable_sub}.
Now suppose instead that $\forall k \in S_1 \setminus S_2$ we have that $\sum_{i \in [N]} A[i, k] (\1 - (Q_2^*\tilde \x_2) [i]) = 0$.
Then $A_1 Q_1Q_2^* \tilde \x_2 = \cp_1$, but $A_1$ is invertible, a contradiction.
So $\exists k \in S_1 \setminus S_2$ so that $\sum_{i \in [N]} A[i, k] (\1 - (Q_2^*\tilde \x_2) [i]) > 0$. 

Let $\eps = \sum_{i \in [N]} A[i, k] (\1 - (Q_2^*\tilde \x_2) [i])$.  By continuity for $\x$ in arbitrarily small neighborhoods of $\tilde \x_2$, then $\dot \x [k] > \frac{\eps}{2} x[k]$.  Thus $\tilde Q_2^*\x_2$ is not attracting in $\R_{++}^N$.
\end{proof}





\bibliographystyle{unsrt} \bibliography{mine,np,gt,SR,cn,grn,prob}

\end{document}